# AI-Based Assistive Navigation Application for the Visually Impaired

## Overview
This project is an assistive navigation application designed to help visually impaired users by providing real-time obstacle detection and voice-controlled navigation. The application runs locally on supported devices, using machine learning (COCO-SSD model) for object detection and integrates OpenStreetMap for navigation support.

The app includes an SOS feature to send live location updates to emergency contacts, enhancing user safety.

---

## Features
- Real-time obstacle detection using the COCO-SSD machine learning model  
- Voice-controlled navigation powered by the Web Speech API  
- Interactive navigation with OpenStreetMap integration  
- SOS alert feature to share live location with emergency contacts  
- Runs as an application on devices with browser support (offline-friendly and user-focused)

---

## Technology Stack
- JavaScript (TensorFlow.js for ML, Web Speech API)  
- HTML & CSS for the user interface  
- COCO-SSD for object detection  
- OpenStreetMap API for maps and navigation  

---

## Project Structure
/assets
/models
index.html
script.js
style.css
README.md

---

## How to Run
1. Download or clone the repository.  
2. Open `index.html` in a modern web browser (Chrome or Firefox recommended).  
3. Allow camera and microphone access when prompted.  
4. Use voice commands to control navigation and detect obstacles.  
5. Use the SOS feature to send your live location to emergency contacts.

## Contact
Saniya  
Email: saniyya164@gmail.com
